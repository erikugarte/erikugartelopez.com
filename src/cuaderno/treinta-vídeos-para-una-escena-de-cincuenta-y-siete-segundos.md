---
title_es: Treinta vídeos para una escena de cincuenta y siete segundos
title_en: Thirty videos for a fifty-seven-second scene
date: 2026-03-02
excerpt_es: En el capítulo dos de *La ballena de oro* hay un accidente. Ya tiene
  palabras y música. Le pedí a una inteligencia artificial que le diera imagen.
  Lo que apareció se parecía a lo que llevo dentro — pero no fue la máquina la
  que acertó.
excerpt_en: In chapter two of *La ballena de oro* there is an accident. It
  already had words and music. I asked an AI to give it image. What appeared
  resembled what I carry inside — but it was not the machine that got it right.
pageDescription: "Tercer post del Cuaderno de Erik Ugarte López. Cómo usé Runway
  para dar imagen al accidente del capítulo dos de La ballena de oro — treinta
  generaciones de vídeo, flores bajo el agua y lo que pasa cuando intentas
  traducir un recuerdo. "
body_en: >-
  En el capítulo dos de La ballena de oro hay un accidente. Es el Día de la
  Madre. Un niño de seis años sale de una floristería con un ramo entre los
  brazos. El padre le ha dicho corre, dale tú el ramo. La madre está al otro
  lado, mirándolo. No mira la carretera — mira las flores. Y al niño con las
  flores. Un coche sale de la curva. El ramo nunca llega.

  Después de ese día, la familia se rompió. No de golpe — los accidentes no rompen familias, sino lo que viene después: el silencio, la culpa, las preguntas que no se contestan. Las flores fueron lo último antes de que todo cambiara. Las flores fueron <span class="marca">lo último que salió entero</span>.

  Ese momento ya tiene palabras — las del capítulo. Tiene música — «El día de las flores», cincuenta y siete segundos donde una voz de niño canta Luz que invade / Motor con dientes / El mundo estira / Pétalos / Aire y una voz adulta cierra con Blancas / Amarillas, porque el color de las flores depende del recuerdo, no de los hechos. La voz de niño canta lo que pasó. La voz de adulto nombra lo que quedó. Pero no tenía imagen. Quise dársela.

  Usé Runway, una herramienta de generación de vídeo por inteligencia artificial. No porque la escena lo necesitara — ya funcionaba sin imagen. Sino porque quería saber qué pasaba cuando intentaba traducir a imagen algo que ya existía como texto y como sonido. Qué aparecía. Qué se resistía.

  Lo primero que tuve claro fue lo que no quería: nada de personas, nada de narrativa explícita, nada de realismo. El accidente no es una escena — es una percepción. La del niño que ve cómo la luz se agranda y las flores se abren en el aire y el mundo se vuelve lento. Lo que buscaba era una imagen onírica del impacto: cámara lenta extrema, pétalos blancos y amarillos suspendidos en luz dorada. Abstracto. Como lo recuerda el cuerpo, no como lo contaría un testigo.

  El primer prompt fue directo: Extreme slow motion, white and yellow flower petals floating through bright sunlight, lens flare, dreamlike, soft focus, petals suspended in air, golden hour light flooding the frame, no people, abstract, ethereal, film grain, 4K cinematic. Funcionó a medias. Runway devolvía pétalos, sí, pero demasiado rápidos, demasiado organizados. Como una publicidad de perfume. El trauma no tiene esa limpieza. De las primeras generaciones no usé casi nada — las flores se movían sin peso, como confeti digital. Probé Topaz para mejorar las cámaras lentas. La calidad bajaba. Lo descarté.

  <span class="marca">Entonces los metí bajo el agua.</span>

  No fue una decisión planificada. Fue una intuición: el accidente es el momento en que <span class="marca">algo se hunde</span>. Las flores del ramo caen, pero en la memoria no caen hacia abajo — se hunden. Como si el aire se convirtiera en agua y todo fuera más denso y más lento. Escribí: High angle wide shot looking down at white and yellow wildflowers sinking through deep blue water. Flowers scattered across the frame, petals separating as they descend. Camera: slow tilt down following their descent. Golden light rays filter from the water surface above.

  Solo después me di cuenta de que el propio capítulo ya terminaba con esa imagen. Las flores del recuerdo se quedan «dando vueltas dentro, como hojas en un vaso de agua». Yo había escrito eso años antes. Cuando le pedí a Runway que hundiera las flores, estaba siguiendo algo que ya estaba en mi propio texto sin saber que lo estaba siguiendo.

  De ese prompt salieron la mayoría de los clips que usé. Generé unas treinta variaciones en total — continuaciones, distintas cámaras, ajustes. Muchas no servían. A veces pedía los pétalos en el aire y Runway los ponía bajo el agua. A veces el final de un clip no daba juego para continuar con el siguiente. La herramienta tiene algo parecido a voluntad propia: no siempre obedece, y lo que devuelve tiene sus propias ideas sobre cómo deben caer las flores.

  Al principio del vídeo, cuando la voz de niño canta pétalos… aire, hay una sola flor en primer plano. Casi sola — apenas unas cuantas diminutas alrededor. Está muy cerca de la superficie, donde la luz todavía entra con fuerza. Y se abre. Despacio. Abre y abre y abre sus pétalos, como esas manos del capítulo que quieren agarrar algo. Después, un fogonazo blanco que lo llena todo — la pantalla entera se vuelve luz. En la canción se oye el golpe. En el capítulo, «una luz que se agrandó de golpe y que llevaba dentro un rugido». Después de esa luz, todo es agua.

  Lo que no esperaba fue lo que las flores hicieron bajo el agua. Algunas parecían bailar. Los pétalos se movían como aletas, y las flores se desplazaban como peces — no cayendo, sino nadando. Hay una en particular que se convierte casi en protagonista: desciende, vuelve a subir, y luego desaparece entre las demás. No la pedí. Apareció. Después, las flores forman algo parecido a un cardumen y nadan hacia delante. En la edición hice que nadaran también hacia atrás — el reverse — y eso les dio un movimiento de ida y vuelta, de respiración, de algo que no termina de decidir si se va o se queda.

  <span class="marca">Flores que se comportan como peces.</span> En una novela que se llama La ballena de oro. Eso no lo planifiqué. No le dije a la máquina que la novela tiene un mundo submarino, ni que el agua es el primer movimiento del ciclo sonoro, ni que hay una ballena dorada que aparece cuando el niño necesita un lugar donde esconderse. Pero las flores lo encontraron solas. O quizá lo encontré yo al verlas, que no es lo mismo pero importa igual.

  Hay un detalle que solo se nota si se presta atención: las imágenes se oscurecen sutilmente de principio a fin. No es evidente — no hay un fundido a negro ni un cambio brusco. Pero al comparar el primer clip con el último, la luz ha cambiado. Como si las flores fueran hundiéndose cada vez más lejos de la superficie. O como si el recuerdo, a medida que avanza, pesara más.

  El montaje fue en Final Cut Pro. Ajustes de color para que el agua tuviera coherencia entre clips sin ser idéntica — porque el recuerdo tampoco lo es. Capas de ajuste. Una capa de grano de película al diez o quince por ciento porque en algunos clips el agua se pixelaba en las zonas oscuras — los degradados de azul se rompían en bloques, y el grano los disimulaba mezclando los tonos. Cámaras lentas hechas a mano cuando Topaz falló. El reverse de la bandada. Y sobre todo: sincronizar cada corte con los golpes de ritmo de la canción. El pico de energía de la canción cae donde el cardumen nada junto. La voz adulta entra cuando las flores empiezan a dispersarse. Eso no lo hace la inteligencia artificial. Eso lo hace el oído de quien sabe qué quiere contar.

  Hacia el final, las flores se van dispersando. Se alejan. Hasta que queda una sola, profunda, lejos de la superficie. Esa última flor se hunde y desaparece. Y entonces la cámara cambia: ya no mira hacia abajo — mira hacia arriba. Desde el fondo. Hacia la superficie. Haces de luz bajan desde lo alto y la luz se intensifica, se acerca, llena el encuadre como un fogonazo. En el capítulo, el niño abre los ojos en el hospital y ve «la lámpara redonda del techo, tan cerca que parecía luna». Después, negro.

  Cuando vi el resultado montado — la flor sola abriéndose cerca de la superficie, las demás hundiéndose, nadando, la voz del niño cantando flores, flores, no llegué, la voz adulta cerrando con blancas, amarillas, la luz yéndose poco a poco, y al final esa mirada hacia arriba — pensé que ahí estaba de nuevo. El mismo momento de siempre. Pero las flores tenían más peso. Bajo el agua eran más densas, más lentas. Como las vi. No como las vi en la realidad del accidente — no recuerdo la realidad. Como las vi siempre: en el recuerdo, donde todo pesa más y las flores nunca terminan de caer.

  Un ramo que nunca llegó a las manos de una madre. Eso es lo que es el vídeo. Una máquina que no sabe nada de eso generó una imagen que se parece a lo que llevo dentro. Pero no fue ella la que acertó — fue <span class="marca">el esfuerzo de intentar explicárselo</span>. En ese esfuerzo, algo se soltó. En el pecho, no en la cabeza. La imagen dejó de ser solo mía. Estaba ahí fuera, visible, como flores que por fin tocan el fondo.

  El vídeo no se había publicado hasta ahora. Empieza con pétalos en la luz. Acaba con <span class="marca">luz sin pétalos</span>. Cincuenta y siete segundos. Como el accidente. Como el tiempo que tarda un recuerdo en recorrerte entero.

  <video controls playsinline width="100%" style="margin: 2em 0;">
    <source src="el-dia-de-las-flores.mp4" type="video/mp4">
  </video>
---
In chapter two of La ballena de oro there is an accident. It is Mother's Day. A six-year-old boy walks out of a flower shop with a bouquet in his arms. His father has told him run, give her the flowers yourself. His mother is on the other side, watching him. She is not looking at the road — she is looking at the flowers. And at the boy carrying the flowers. A car comes round the bend. The bouquet never arrives.
After that day, the family broke apart. Not at once — accidents do not break families, but what comes after does: the silence, the guilt, the questions no one answers. The flowers were the last thing before everything changed. The flowers were <span class="marca">the last thing that came out whole</span>.
That moment already has words — the chapter's words. It has music — "El día de las flores," fifty-seven seconds where a child's voice sings Luz que invade / Motor con dientes / El mundo estira / Pétalos / Aire and an adult voice closes with Blancas / Amarillas, because the colour of the flowers depends on the memory, not the facts. The child's voice sings what happened. The adult voice names what remained. But it had no image. I wanted to give it one.
I used Runway, an AI video generation tool. Not because the scene needed it — it already worked without image. But because I wanted to know what happened when I tried to translate into moving image something that already existed as text and as sound. What would appear. What would resist.
The first thing I was sure of was what I did not want: no people, no explicit narrative, no realism. The accident is not a scene — it is a perception. The child's perception as the light expands and the petals open in the air and the world slows down. What I was after was an oneiric image of impact: extreme slow motion, white and yellow petals suspended in golden light. Abstract. The way the body remembers it, not the way a witness would tell it.
The first prompt was straightforward: Extreme slow motion, white and yellow flower petals floating through bright sunlight, lens flare, dreamlike, soft focus, petals suspended in air, golden hour light flooding the frame, no people, abstract, ethereal, film grain, 4K cinematic. It half-worked. Runway returned petals, yes, but too fast, too neat. Like a perfume advert. Trauma does not have that cleanliness. From those first generations I used almost nothing — the flowers moved without weight, like digital confetti. I tried Topaz to improve the slow motions. Quality dropped. I discarded it.
<span class="marca">Then I put them underwater.</span>
It was not a planned decision. It was instinct: the accident is the moment <span class="marca">something sinks</span>. The flowers fall, but in memory they do not fall downward — they sink. As if the air had turned to water and everything were denser and slower. I wrote: High angle wide shot looking down at white and yellow wildflowers sinking through deep blue water. Flowers scattered across the frame, petals separating as they descend. Camera: slow tilt down following their descent. Golden light rays filter from the water surface above.
Only later did I realise that the chapter itself already ended with that image. The flowers in memory are left "spinning inside, like leaves in a glass of water." I had written that years before. When I asked Runway to sink the flowers, I was following something already in my own text without knowing I was following it.
Most of the clips I ended up using came from that prompt. I generated around thirty variations in total — continuations, different cameras, adjustments. Many were useless. Sometimes I asked for petals in the air and Runway placed them underwater. Sometimes the end of a clip left no room to continue into the next. The tool has something resembling a will of its own: it does not always obey, and what it returns has its own ideas about how flowers should fall.
At the start of the video, when the child's voice sings pétalos… aire, there is a single flower in close-up. Almost alone — just a few tiny ones scattered around it. It is very near the surface, where the light still enters with force. And it opens. Slowly. Opens and opens and opens its petals, like those hands in the chapter that want to grab hold of something. Then a white flash fills the entire screen — pure light. In the song you can hear the blow. In the chapter, "a light that grew suddenly and carried a roar inside it." After that light, everything is water.
What I did not expect was what the flowers did underwater. Some of them seemed to dance. The petals moved like fins, and the flowers drifted like fish — not falling, but swimming. One in particular became almost a protagonist: it descended, rose back up, then disappeared among the others. I did not ask for it. It appeared. Later, the flowers formed something like a shoal and swam forward. In the edit I made them swim backward too — the reverse — which gave them a back-and-forth motion, a breathing, the movement of something that cannot decide whether it is leaving or staying.
<span class="marca">Flowers behaving like fish.</span> In a novel called The Golden Whale. I did not plan that. I never told the machine that the novel contains an underwater world, or that water is the first movement of the sonic cycle, or that there is a golden whale that appears when the boy needs somewhere to hide. But the flowers found it on their own. Or perhaps I found it when I saw them, which is not the same thing but matters just as much.
There is a detail only visible if you pay attention: the images darken subtly from beginning to end. It is not obvious — there is no fade to black, no sudden shift. But if you compare the first clip with the last, the light has changed. As though the flowers were sinking further from the surface. Or as though the memory, as it progresses, weighs more.
The edit happened in Final Cut Pro. Colour adjustments so the water had coherence between clips without being identical — because memory is not identical either. Adjustment layers. A film grain layer at ten or fifteen per cent because in some clips the water pixelated in the dark areas — the blue gradients broke into blocks, and the grain disguised them by blending the tones. Slow motions done by hand after Topaz failed. The reverse of the shoal. And above all: syncing every cut to the rhythmic hits of the song. The song's peak of energy falls where the shoal swims together. The adult voice enters as the flowers begin to scatter. AI does not do that. The ear does — the ear of someone who knows what they want to tell.
Toward the end, the flowers scatter. They drift apart. Until only one remains, deep, far from the surface. That last flower sinks and disappears. And then the camera changes: it is no longer looking down — it is looking up. From the bottom. Toward the surface. Shafts of light descend from above and the light intensifies, grows closer, fills the frame like a flash. In the chapter, the boy opens his eyes in hospital and sees "the round ceiling lamp, so close it looked like the moon." Then black.
When I saw the assembled result — the lone flower opening near the surface, the rest sinking, swimming, the child's voice singing flores, flores, no llegué, the adult voice closing with blancas, amarillas, the light slowly leaving, and at the end that upward gaze — I thought: there it is again. The same moment as always. But the flowers had more weight. Underwater they were denser, slower. The way I saw them. Not the way I saw them in the reality of the accident — I don't remember the reality. The way I have always seen them: in memory, where everything weighs more and the flowers never finish falling.
A bouquet that never reached a mother's hands. That is what the video is. A machine that knows nothing about any of this generated an image that resembles what I carry inside. But it was not the machine that got it right — it was <span class="marca">the effort of trying to explain it</span>. In that effort, something let go. In the chest, not in the head. The image was no longer only mine. It was out there, visible, like flowers that finally touch the bottom.
The video had not been published until now. It begins with petals in the light. It ends with <span class="marca">light without petals</span>. Fifty-seven seconds. Like the accident. Like the time it takes a memory to travel through you whole.
<video controls playsinline width="100%" style="margin: 2em 0;">
  <source src="el-dia-de-las-flores.mp4" type="video/mp4">
</video>
